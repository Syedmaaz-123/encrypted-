{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90572ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator:\n",
    "    \"\"\"Wrapper for AI image generation.\"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cpu\", use_dummy=True):\n",
    "        self.device = device\n",
    "        self.use_dummy = use_dummy\n",
    "        self.pipeline = None\n",
    "\n",
    "        if not self.use_dummy:\n",
    "            try:\n",
    "                from diffusers import StableDiffusionPipeline\n",
    "\n",
    "                self.pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "                    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16\n",
    "                )\n",
    "                self.pipeline = self.pipeline.to(self.device)\n",
    "            except ImportError:\n",
    "                print(\"Diffusers not installed. Falling back to dummy generator.\")\n",
    "                self.use_dummy = True\n",
    "\n",
    "    def generate_cover(\n",
    "        self,\n",
    "        prompt=\"A beautiful realistic landscape photo, 4k resolution\",\n",
    "        size=(256, 256),\n",
    "    ):\n",
    "        if self.use_dummy or self.pipeline is None:\n",
    "            img_tensor = (\n",
    "                torch.rand((3, size[0], size[1]), dtype=torch.float32)\n",
    "                .to(self.device)\n",
    "                .unsqueeze(0)\n",
    "            )\n",
    "            import torch.nn.functional as F\n",
    "\n",
    "            img_tensor = F.avg_pool2d(\n",
    "                img_tensor, kernel_size=5, stride=1, padding=2\n",
    "            ).squeeze(0)\n",
    "            return (img_tensor - img_tensor.min()) / (\n",
    "                img_tensor.max() - img_tensor.min()\n",
    "            )\n",
    "        else:\n",
    "            image = self.pipeline(\n",
    "                prompt, height=size[0], width=size[1], num_inference_steps=20\n",
    "            ).images[0]\n",
    "            image_np = np.array(image).astype(np.float32) / 255.0\n",
    "            return torch.from_numpy(image_np).permute(2, 0, 1).to(self.device)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
