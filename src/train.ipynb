{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d520939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_autoencoder import VideoAutoencoder\n",
    "from stego_networks import (\n",
    "    HiderNetwork,\n",
    "    RevealerNetwork,\n",
    "    format_secret_for_hiding,\n",
    "    extract_secret_from_prediction,\n",
    ")\n",
    "from image_generator import ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee675576",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVideoDataset(Dataset):\n",
    "    def __init__(self, num_samples=100, frames=16, height=64, width=64):\n",
    "        self.num_samples = num_samples\n",
    "        self.frames = frames\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.rand(\n",
    "            (3, self.frames, self.height, self.width), dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec2841",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealVideoDataset(Dataset):\n",
    "    \"\"\"Loads actual .mp4 or .avi videos from a directory for autoencoder training.\"\"\"\n",
    "    def __init__(self, directory, frames=16, height=64, width=64):\n",
    "        self.video_paths = glob.glob(os.path.join(directory, \"**\", \"*.avi\"), recursive=True) + \\\n",
    "                           glob.glob(os.path.join(directory, \"**\", \"*.mp4\"), recursive=True)\n",
    "        self.frames = frames\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((self.height, self.width)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cap = cv2.VideoCapture(self.video_paths[idx])\n",
    "        frames = []\n",
    "        while len(frames) < self.frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_tensor = self.transform(frame) # shape (3, H, W)\n",
    "            frames.append(frame_tensor)\n",
    "        cap.release()\n",
    "        \n",
    "        # If video is too short, pad it with the last frame\n",
    "        while len(frames) < self.frames and len(frames) > 0:\n",
    "            frames.append(frames[-1])\n",
    "            \n",
    "        # If video couldn't be loaded at all, return zeros (edge case fallback)\n",
    "        if len(frames) == 0:\n",
    "            return torch.zeros((3, self.frames, self.height, self.width), dtype=torch.float32)\n",
    "            \n",
    "        # Stack into (C, F, H, W)\n",
    "        video_tensor = torch.stack(frames, dim=1)\n",
    "        return video_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b40c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_video_autoencoder(model, dataloader, epochs=5, device=\"cpu\"):\n",
    "    print(\"--- Training Video Autoencoder ---\")\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), \"../models/video_autoencoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e66fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stego_networks(\n",
    "    hider, revealer, image_generator, epochs=5, device=\"cpu\", secret_dim=4096\n",
    "):\n",
    "    print(\"\\\\n--- Training Steganography Networks ---\")\n",
    "    hider.to(device)\n",
    "    revealer.to(device)\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    criterion_bce = nn.BCELoss()\n",
    "    optimizer = optim.Adam(\n",
    "        list(hider.parameters()) + list(revealer.parameters()), lr=1e-3\n",
    "    )\n",
    "    batch_size = 4\n",
    "    iterations = 20\n",
    "    for epoch in range(epochs):\n",
    "        hider.train()\n",
    "        revealer.train()\n",
    "        img_loss = 0.0\n",
    "        bit_loss = 0.0\n",
    "        for _ in range(iterations):\n",
    "            covers = torch.stack(\n",
    "                [image_generator.generate_cover(size=(256, 256)) for _ in range(batch_size)]\n",
    "            ).to(device)\n",
    "            secret_bits = (\n",
    "                torch.randint(0, 2, (batch_size, secret_dim)).float().to(device)\n",
    "            )\n",
    "            spatial_secret = format_secret_for_hiding(\n",
    "                secret_bits, (batch_size, 1, 256, 256)\n",
    "            )\n",
    "            stego = hider(covers, spatial_secret)\n",
    "            secret_pred = extract_secret_from_prediction(revealer(stego), secret_dim)\n",
    "            l_img = criterion_mse(stego, covers)\n",
    "            l_bit = criterion_bce(secret_pred, secret_bits)\n",
    "            loss = (10.0 * l_img) + l_bit\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            img_loss += l_img.item()\n",
    "            bit_loss += l_bit.item()\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}, Img Loss: {img_loss/iterations:.4f}, Bit Loss: {bit_loss/iterations:.4f}\"\n",
    "        )\n",
    "    torch.save(hider.state_dict(), \"../models/hider.pth\")\n",
    "    torch.save(revealer.state_dict(), \"../models/revealer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c986423",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\") # Uses Apple Silicon GPU!\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # -------------------------------------------------------------\n",
    "    # 1. SETUP: CHOOSE DUMMY DATA OR REAL DATA\n",
    "    # -------------------------------------------------------------\n",
    "    # Change this to True when you have downloaded the datasets!\n",
    "    USE_REAL_DATA = True \n",
    "    \n",
    "    # Define paths to your downloaded folders\n",
    "    VIDEO_DATASET_PATH = \"/Users/syedmaaz/project/data/dataset /UCF101/\" # Folder containing .mp4 or .avi\n",
    "    \n",
    "    if USE_REAL_DATA:\n",
    "        print(\"Loading REAL Video Dataset... (This might take a moment)\")\n",
    "        # Load your real video dataset and create a dataloader\n",
    "        video_dataset = RealVideoDataset(directory=VIDEO_DATASET_PATH, frames=16)\n",
    "        video_loader = DataLoader(video_dataset, batch_size=4, shuffle=True)\n",
    "    else:\n",
    "        print(\"Loading DUMMY Video Dataset... (For quick testing)\")\n",
    "        video_dataset = DummyVideoDataset(num_samples=20)\n",
    "        video_loader = DataLoader(video_dataset, batch_size=4)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # 2. RUN AUTOENCODER TRAINING\n",
    "    # -------------------------------------------------------------\n",
    "    ae = VideoAutoencoder(3, 256)\n",
    "    train_video_autoencoder(ae, video_loader, epochs=2, device=device)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # 3. RUN STEGANOGRAPHY NETWORKS TRAINING\n",
    "    # -------------------------------------------------------------\n",
    "    # For Stego networks, Stable Diffusion `ImageGenerator(use_dummy=not USE_REAL_DATA)` \n",
    "    # will handle real cover images if USE_REAL_DATA=True!\n",
    "    hider = HiderNetwork(3, 1, 32)\n",
    "    revealer = RevealerNetwork(3, 1, 32)\n",
    "    img_gen = ImageGenerator(device, use_dummy=not USE_REAL_DATA)\n",
    "    \n",
    "    train_stego_networks(\n",
    "        hider,\n",
    "        revealer,\n",
    "        img_gen,\n",
    "        epochs=2,\n",
    "        device=device,\n",
    "        secret_dim=8416, \n",
    "    )\n",
    "    print(\"Training Complete!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
